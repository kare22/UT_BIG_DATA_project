{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f48efcf-cc38-4f99-8427-6d9234a01562",
   "metadata": {},
   "source": [
    "# Data enrichment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830b41fa-1f4c-450b-ae9f-3addfe014d14",
   "metadata": {},
   "source": [
    "* Join prickup and dropoff coordinates with location name\n",
    "* Convert datetimes to timestamps\n",
    "* Save the result in `../output/output.parquet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28c6727ab8b783bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T05:17:37.498548Z",
     "start_time": "2025-02-27T05:17:37.300599Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from sedona.utils import SedonaKryoRegistrator\n",
    "from pyspark.sql.functions import col, udf, unix_timestamp, to_timestamp\n",
    "from pyspark.sql.functions import expr\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, IntegerType\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely import Point\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a3f0c5b-f3d0-49d7-89a8-45bd4a7fe5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sedona_jar = '/home/jovyan/jars/sedona-spark-shaded-3.0_2.12-1.6.1.jar'\n",
    "geotools_jar = '/home/jovyan/jars/geotools-wrapper-1.7.0-28.5.jar'\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "        .config(\"spark.jars\", f\"{sedona_jar},{geotools_jar}\") \n",
    "        .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\")\n",
    "        .config(\"spark.kryo.registrator\", SedonaKryoRegistrator.getName)\n",
    "        .config(\"spark.sql.extensions\", \"org.apache.sedona.sql.SedonaSqlExtensions\")\n",
    "        .config(\"spark.driver.memory\", \"8g\")\n",
    "        .config(\"spark.executor.memory\", \"8g\")\n",
    "        .appName('NYC Taxi')    \n",
    "        .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ced6ca-59a7-4db1-8fb6-5b94f60c05bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ready_path = '../output/data_ready.parquet'\n",
    "data_ready_file = Path(data_ready_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f8f404b-8a3f-4c66-8435-2330fc746910",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not data_ready_file.exists():\n",
    "    schema = StructType([\n",
    "        StructField(\"medallion\", StringType(), True),\n",
    "        StructField(\"hack_license\", StringType(), True),\n",
    "        StructField(\"vendor_id\", StringType(), True),\n",
    "        StructField(\"rate_code\", IntegerType(), True),\n",
    "        StructField(\"store_and_fwd_flag\", StringType(), True),\n",
    "        StructField(\"pickup_datetime\", StringType(), True),\n",
    "        StructField(\"dropoff_datetime\", StringType(), True),\n",
    "        StructField(\"passenger_count\", IntegerType(), True),\n",
    "    \n",
    "        StructField(\"trip_time_in_secs\", StringType(), True),\n",
    "        StructField(\"trip_distance\", StringType(), True),\n",
    "        \n",
    "        StructField(\"pickup_longitude\", StringType(), True),\n",
    "        StructField(\"pickup_latitude\", StringType(), True),\n",
    "        StructField(\"dropoff_longitude\", StringType(), True),\n",
    "        StructField(\"dropoff_latitude\", StringType(), True)\n",
    "    ])\n",
    "    \n",
    "    data_path = '../output/data.parquet'\n",
    "    data_file = Path(data_path)\n",
    "    if not data_file.exists():\n",
    "        csv_data = spark.read.csv('../data/trip_data/*.csv', header=True, schema=schema)\n",
    "        cols = [\"medallion\", \"pickup_datetime\", \"dropoff_datetime\", \"pickup_longitude\", \"pickup_latitude\", \"dropoff_longitude\", \"dropoff_latitude\"]\n",
    "        csv_data_cols = csv_data.selectExpr(cols)\n",
    "        csv_data_cleaned = csv_data_cols.dropna(subset=cols)\n",
    "        csv_data_cleaned.write.mode('overwrite').parquet(data_path)\n",
    "    \n",
    "    df_trip = spark.read.load(data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7efd448-2715-4b38-8d7a-7bf6c3fb392f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert pcikup and dropoff time to timestamps\n",
    "\n",
    "if not data_ready_file.exists():\n",
    "    DATE_FORMAT = 'yyyy-MM-d HH:mm:ss'\n",
    "    df_trip_w_ts = (df_trip\n",
    "             .withColumn('pickup_ts', unix_timestamp(to_timestamp(col(\"pickup_datetime\"), DATE_FORMAT)))\n",
    "             .withColumn('dropoff_ts', unix_timestamp(to_timestamp(col(\"dropoff_datetime\"), DATE_FORMAT)))\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcee672bd4982637",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T05:17:46.660044Z",
     "start_time": "2025-02-27T05:17:39.088670Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load spatial data of NY\n",
    "\n",
    "if not data_ready_file.exists():\n",
    "    # First we use geopandas to read the geojson\n",
    "    gdf = gpd.read_file('../data/nyc-boroughs.geojson')\n",
    "    \n",
    "    # Convert geom to WKT\n",
    "    gdf['geom'] = gdf['geometry'].apply(lambda geom: geom.wkt if geom else None)\n",
    "    \n",
    "    # geopandas df to pandas df\n",
    "    pdf = gdf.astype(str)\n",
    "    \n",
    "    # pandas df to spark df\n",
    "    df_geom = spark.createDataFrame(pdf)\n",
    "    \n",
    "    # Convert WKT to geom (format) which is used for intersections\n",
    "    df_geom = df_geom.withColumn(\"geom\", expr(\"ST_GeomFromWKT(geom)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9cf98cb-c783-4515-90e8-13059c64821f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not data_ready_file.exists():\n",
    "    # Helper function to convert long and lat to Point\n",
    "    udf_to_point = udf(lambda lon, lat: Point(lon, lat).wkt if lon is not None and lat is not None else '')\n",
    "    \n",
    "    # Trip df to WKT -> geom \n",
    "    df_trip_w_points = (df_trip_w_ts\n",
    "         .withColumn('pickup_point', udf_to_point(col('pickup_longitude'), col('pickup_latitude')))\n",
    "         .withColumn('dropoff_point', udf_to_point(col('dropoff_longitude'), col('dropoff_latitude')))\n",
    "         .withColumn('geom_pickup', expr('ST_GeomFromWKT(pickup_point)'))\n",
    "         .withColumn('geom_dropoff', expr('ST_GeomFromWKT(dropoff_point)'))\n",
    "        )\n",
    "    \n",
    "    df_geom = df_geom.repartition(40)\n",
    "    df_trip_w_points = df_trip_w_points.repartition(40)\n",
    "    \n",
    "    # Join geospatial data to trip pickup locations\n",
    "    df_trip_w_pickup = df_geom.alias('geo').join(\n",
    "        df_trip_w_points.alias('travel'),\n",
    "        expr('ST_Intersects(geo.geom, travel.geom_pickup)'),\n",
    "        'inner'\n",
    "    )\n",
    "    \n",
    "    # Distinguish pickup borough\n",
    "    df_trip_w_pickup = df_trip_w_pickup.withColumn('pickup_borough', col('borough'))\n",
    "    \n",
    "    # Remove excess columns from pickup\n",
    "    df_trip_w_pickup = df_trip_w_pickup.drop(\"geometry\", \"@id\", \"geom\", \"borough\", \"boroughCode\")\n",
    "    \n",
    "    # Join geospatial data to trip dropoff locations\n",
    "    df_trip_w_pickup_n_dropoff = df_geom.alias('geo').join(\n",
    "        df_trip_w_pickup.alias('travel'),\n",
    "        expr('ST_Intersects(geo.geom, travel.geom_dropoff)'),\n",
    "        'inner'\n",
    "    )\n",
    "    \n",
    "    # Distinguish dropoff borough\n",
    "    df_trip_w_pickup_n_dropoff = df_trip_w_pickup_n_dropoff.withColumn('dropoff_borough', col('borough'))\n",
    "    \n",
    "    df_final = df_trip_w_pickup_n_dropoff.select(\"medallion\", \"pickup_borough\", \"dropoff_borough\", \"pickup_ts\", \"dropoff_ts\")\n",
    "    df_final.write.mode('overwrite').parquet(data_ready_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
