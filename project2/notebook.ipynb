{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63ac151b-3b3a-4238-9a5b-3e5dca122326",
   "metadata": {},
   "source": [
    "# Project 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bdea92-a01b-4f20-baa7-e5495f1f63c3",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cab86fdf-de40-4796-b00c-d4da3e65bc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import from_json, col, floor, window, concat_ws\n",
    "from pyspark.sql.types import StructType, StringType, DoubleType, TimestampType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c90f46d-8d4f-4609-b662-2d9ed30574af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SparkSession with the Kafka JAR\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"KafkaTaxiStream\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"âœ… Spark Session created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a407f2b8-4c63-412c-9c90-8a25f05655e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Schema for Incoming Data\n",
    "schema = StructType() \\\n",
    "    .add(\"medallion\", StringType()) \\\n",
    "    .add(\"hack_license\", StringType()) \\\n",
    "    .add(\"pickup_datetime\", TimestampType()) \\\n",
    "    .add(\"dropoff_datetime\", TimestampType()) \\\n",
    "    .add(\"trip_time_in_secs\", DoubleType()) \\\n",
    "    .add(\"trip_distance\", DoubleType()) \\\n",
    "    .add(\"pickup_longitude\", DoubleType()) \\\n",
    "    .add(\"pickup_latitude\", DoubleType()) \\\n",
    "    .add(\"dropoff_longitude\", DoubleType()) \\\n",
    "    .add(\"dropoff_latitude\", DoubleType()) \\\n",
    "    .add(\"payment_type\", StringType()) \\\n",
    "    .add(\"fare_amount\", DoubleType()) \\\n",
    "    .add(\"surcharge\", DoubleType()) \\\n",
    "    .add(\"mta_tax\", DoubleType()) \\\n",
    "    .add(\"tip_amount\", DoubleType()) \\\n",
    "    .add(\"tolls_amount\", DoubleType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Kafka stream\n",
    "taxi_stream = spark \\\n",
    "    .readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"kafka:9092\") \\\n",
    "    .option(\"subscribe\", \"taxi-trips\") \\\n",
    "    .option(\"startingOffsets\", \"earliest\") \\\n",
    "    .load()\n",
    "\n",
    "# Parse JSON\n",
    "parsed_taxi_stream = taxi_stream.selectExpr(\"CAST(value AS STRING) as json_str\") \\\n",
    "    .select(from_json(col(\"json_str\"), schema).alias(\"data\")) \\\n",
    "    .select(\"data.*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2bc510-4ddc-45ed-aaf1-8a33fd614d03",
   "metadata": {},
   "source": [
    "# Query 0: Data Cleansing and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1dd0a5-68d2-45c0-8842-1768f91c9431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove malformed and invalid data\n",
    "cleaned_taxi_stream = parsed_taxi_stream \\\n",
    "    .filter(\"medallion IS NOT NULL AND hack_license IS NOT NULL\") \\\n",
    "    .filter(\"pickup_longitude != 0.0 AND pickup_latitude != 0.0\") \\\n",
    "    .filter(\"dropoff_longitude != 0.0 AND dropoff_latitude != 0.0\") \\\n",
    "    .filter(\"pickup_longitude BETWEEN -74.913585 AND -73.0\") \\\n",
    "    .filter(\"pickup_latitude BETWEEN 40.0 AND 41.474937\") \\\n",
    "    .filter(\"dropoff_longitude BETWEEN -74.913585 AND -73.0\") \\\n",
    "    .filter(\"dropoff_latitude BETWEEN 40.0 AND 41.474937\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5968d8ef-d0e3-420d-9f67-256e35d05ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = cleaned_taxi_stream.writeStream \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .format(\"memory\") \\\n",
    "    .queryName(\"taxi_trips_cleaned\") \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4abc85-cefc-40c3-a1d6-95f6ba11ad9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View cleansed stream in notebook\n",
    "spark.sql(\"SELECT * FROM taxi_trips_cleaned\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4555b6a1-5a5c-4d2c-b392-79977f2b3c89",
   "metadata": {},
   "source": [
    "# Query 2: Profitable Areas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f88189-8394-463e-9114-c6aad07b6c75",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37e0f61-17e8-4e07-a543-fec9aa875975",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyproj import Transformer\n",
    "from shapely.geometry import Point\n",
    "from pyspark.sql.functions import udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ba2a62-05a0-46d4-9617-a9876b8e08da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform latitude and longitude to UTM meters, accurate for NYC\n",
    "transformer = Transformer.from_crs(\"EPSG:4326\", \"EPSG:32618\", always_xy=True)\n",
    "\n",
    "reference_lat = 41.474937\n",
    "reference_lon = -74.913585\n",
    "\n",
    "# convert the centre of cell 1.1 to meters\n",
    "origin_x, origin_y = transformer.transform(reference_lon, reference_lat)\n",
    "cell_size_meters = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cc6b1a-4ad4-4e4d-a7c8-caf0d2c6a450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to calculate how far the location is from the origin\n",
    "def get_cell_id(lat, lon):\n",
    "    if lat is None or lon is None:\n",
    "        return None\n",
    "    try:\n",
    "        x, y = transformer.transform(lon, lat)\n",
    "        dx = int((x - origin_x) // cell_size_meters) + 1 # how many cells east\n",
    "        dy = int((origin_y - y) // cell_size_meters) + 1 # how many cells south\n",
    "        if 1 <= dx <= 600 and 1 <= dy <= 600: # validate\n",
    "            return f\"{dx}.{dy}\" # put together\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# create spark udf\n",
    "get_cell_udf = udf(get_cell_id, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c843e763-11a8-4e28-80b7-9da7334fcd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take cleaned taxi stream data and convert pickup and dropoff locations into start and end cell IDs\n",
    "stream_with_cells = cleaned_taxi_stream \\\n",
    "    .withColumn(\"start_cell_id\", get_cell_udf(\"pickup_latitude\", \"pickup_longitude\")) \\\n",
    "    .withColumn(\"end_cell_id\", get_cell_udf(\"dropoff_latitude\", \"dropoff_longitude\")) \\\n",
    "    .filter(\"start_cell_id IS NOT NULL AND end_cell_id IS NOT NULL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ea44ef-8517-4a7f-842b-266c1768f25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of rides for each route in the last 30 minutes \n",
    "frequent_routes = stream_with_cells \\\n",
    "    .withWatermark(\"dropoff_datetime\", \"30 minutes\") \\\n",
    "    .groupBy(\n",
    "        window(col(\"dropoff_datetime\"), \"30 minutes\"),\n",
    "        col(\"start_cell_id\"),\n",
    "        col(\"end_cell_id\")\n",
    "    ) \\\n",
    "    .count() \\\n",
    "    .select(\"window\", \"start_cell_id\", \"end_cell_id\", \"count\") \\\n",
    "    .orderBy(col(\"count\").desc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3219b4-8d30-4041-83df-2e24cb3df4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store results in top_routes table\n",
    "frequent_routes.writeStream \\\n",
    "    .outputMode(\"complete\") \\\n",
    "    .format(\"memory\") \\\n",
    "    .queryName(\"top_routes\") \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01aa8050-4b84-42e4-ba22-467f860def02",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT * FROM top_routes LIMIT 10\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3606acfe-c410-4d22-80ab-8a09cd9129f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
