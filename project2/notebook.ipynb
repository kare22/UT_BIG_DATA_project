{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63ac151b-3b3a-4238-9a5b-3e5dca122326",
   "metadata": {},
   "source": [
    "# Project 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bdea92-a01b-4f20-baa7-e5495f1f63c3",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cab86fdf-de40-4796-b00c-d4da3e65bc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import from_json, col, floor, window, concat_ws\n",
    "from pyspark.sql.types import StructType, StringType, DoubleType, TimestampType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c90f46d-8d4f-4609-b662-2d9ed30574af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Spark Session created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Initialize SparkSession with the Kafka JAR\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"KafkaTaxiStream\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"✅ Spark Session created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a407f2b8-4c63-412c-9c90-8a25f05655e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Schema for Incoming Data\n",
    "schema = StructType() \\\n",
    "    .add(\"medallion\", StringType()) \\\n",
    "    .add(\"hack_license\", StringType()) \\\n",
    "    .add(\"pickup_datetime\", TimestampType()) \\\n",
    "    .add(\"dropoff_datetime\", TimestampType()) \\\n",
    "    .add(\"trip_time_in_secs\", DoubleType()) \\\n",
    "    .add(\"trip_distance\", DoubleType()) \\\n",
    "    .add(\"pickup_longitude\", DoubleType()) \\\n",
    "    .add(\"pickup_latitude\", DoubleType()) \\\n",
    "    .add(\"dropoff_longitude\", DoubleType()) \\\n",
    "    .add(\"dropoff_latitude\", DoubleType()) \\\n",
    "    .add(\"payment_type\", StringType()) \\\n",
    "    .add(\"fare_amount\", DoubleType()) \\\n",
    "    .add(\"surcharge\", DoubleType()) \\\n",
    "    .add(\"mta_tax\", DoubleType()) \\\n",
    "    .add(\"tip_amount\", DoubleType()) \\\n",
    "    .add(\"tolls_amount\", DoubleType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Kafka stream\n",
    "taxi_stream = spark \\\n",
    "    .readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"kafka:9092\") \\\n",
    "    .option(\"subscribe\", \"taxi-trips\") \\\n",
    "    .option(\"startingOffsets\", \"earliest\") \\\n",
    "    .load()\n",
    "\n",
    "# Parse JSON\n",
    "parsed_taxi_stream = taxi_stream.selectExpr(\"CAST(value AS STRING) as json_str\") \\\n",
    "    .select(from_json(col(\"json_str\"), schema).alias(\"data\")) \\\n",
    "    .select(\"data.*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2bc510-4ddc-45ed-aaf1-8a33fd614d03",
   "metadata": {},
   "source": [
    "# Query 0: Data Cleansing and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a1dd0a5-68d2-45c0-8842-1768f91c9431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove malformed and invalid data\n",
    "cleaned_taxi_stream = parsed_taxi_stream \\\n",
    "    .filter(\"medallion IS NOT NULL AND hack_license IS NOT NULL\") \\\n",
    "    .filter(\"pickup_longitude != 0.0 AND pickup_latitude != 0.0\") \\\n",
    "    .filter(\"dropoff_longitude != 0.0 AND dropoff_latitude != 0.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5968d8ef-d0e3-420d-9f67-256e35d05ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = cleaned_taxi_stream.writeStream \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .format(\"memory\") \\\n",
    "    .queryName(\"taxi_trips_cleaned\") \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e4abc85-cefc-40c3-a1d6-95f6ba11ad9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+---------------+----------------+-----------------+-------------+----------------+---------------+-----------------+----------------+------------+-----------+---------+-------+----------+------------+\n",
      "|medallion|hack_license|pickup_datetime|dropoff_datetime|trip_time_in_secs|trip_distance|pickup_longitude|pickup_latitude|dropoff_longitude|dropoff_latitude|payment_type|fare_amount|surcharge|mta_tax|tip_amount|tolls_amount|\n",
      "+---------+------------+---------------+----------------+-----------------+-------------+----------------+---------------+-----------------+----------------+------------+-----------+---------+-------+----------+------------+\n",
      "+---------+------------+---------------+----------------+-----------------+-------------+----------------+---------------+-----------------+----------------+------------+-----------+---------+-------+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View cleansed stream in notebook\n",
    "spark.sql(\"SELECT * FROM taxi_trips_cleaned\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4555b6a1-5a5c-4d2c-b392-79977f2b3c89",
   "metadata": {},
   "source": [
    "# Query 1: Frequent Routes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f88189-8394-463e-9114-c6aad07b6c75",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d37e0f61-17e8-4e07-a543-fec9aa875975",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2ba2a62-05a0-46d4-9617-a9876b8e08da",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_lat = 41.474937\n",
    "reference_lon = -74.913585\n",
    "total_cells = 300\n",
    "\n",
    "# Cell sizes\n",
    "cell_size_lat_deg = 0.004491556  # 500m south\n",
    "cell_size_lon_deg = 0.005986     # 500m east"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80cc6b1a-4ad4-4e4d-a7c8-caf0d2c6a450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to calculate how far the location is from the origin\n",
    "def get_cell_id(lat, lon):\n",
    "    if lat is None or lon is None:\n",
    "        return None\n",
    "    try:\n",
    "        dx = int((lon - reference_lon) / cell_size_lon_deg) + 1 # how many cells east\n",
    "        dy = int((reference_lat - lat) / cell_size_lat_deg) + 1 # how many cells south\n",
    "        if 1 <= dx <= total_cells and 1 <= dy <= total_cells: # validate\n",
    "            return f\"{dx}.{dy}\"\n",
    "        else:\n",
    "            return None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# create spark udf\n",
    "get_cell_udf = udf(get_cell_id, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c843e763-11a8-4e28-80b7-9da7334fcd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take cleaned taxi stream data and convert pickup and dropoff locations into start and end cell IDs\n",
    "stream_with_cells = cleaned_taxi_stream \\\n",
    "    .withColumn(\"start_cell_id\", get_cell_udf(\"pickup_latitude\", \"pickup_longitude\")) \\\n",
    "    .withColumn(\"end_cell_id\", get_cell_udf(\"dropoff_latitude\", \"dropoff_longitude\")) \\\n",
    "    .filter(\"start_cell_id IS NOT NULL AND end_cell_id IS NOT NULL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21ea44ef-8517-4a7f-842b-266c1768f25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of rides for each route in the last 30 minutes \n",
    "frequent_routes = stream_with_cells \\\n",
    "    .withWatermark(\"dropoff_datetime\", \"30 minutes\") \\\n",
    "    .groupBy(\n",
    "        window(col(\"dropoff_datetime\"), \"30 minutes\"),\n",
    "        col(\"start_cell_id\"),\n",
    "        col(\"end_cell_id\")\n",
    "    ) \\\n",
    "    .count() \\\n",
    "    .select(\"start_cell_id\", \"end_cell_id\", \"count\") \\\n",
    "    .orderBy(col(\"count\").desc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad3219b4-8d30-4041-83df-2e24cb3df4b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.query.StreamingQuery at 0x7f53c05b3e10>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store results\n",
    "frequent_routes.writeStream \\\n",
    "    .outputMode(\"complete\") \\\n",
    "    .format(\"memory\") \\\n",
    "    .queryName(\"top_routes\") \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01aa8050-4b84-42e4-ba22-467f860def02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+-----+\n",
      "|start_cell_id|end_cell_id|count|\n",
      "+-------------+-----------+-----+\n",
      "+-------------+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM top_routes LIMIT 10\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d9299a-ce45-455c-a4a6-311f47ac8c48",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1138b680-2314-4517-8694-9e2013bf7205",
   "metadata": {},
   "source": [
    "# Query 2: Profitable Areas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71532313-5144-4e9f-b28d-8c55da28057d",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52959a9c-7791-4604-a655-bcf5cc28e2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc3425dc-2fc8-4b67-977f-3d5816f61051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set variables for query 2\n",
    "\n",
    "# divide last query 1 degrees by 2\n",
    "cell_size_lat_deg = 0.002245778   # 250m south\n",
    "cell_size_lon_deg = 0.002993      # 250m east\n",
    "\n",
    "total_cells = 600\n",
    "\n",
    "# create user defined function again with new variables\n",
    "get_cell_udf = udf(get_cell_id, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d086e526-fab5-46ab-ace1-91eb86e41408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start by computing the profit for start cell \n",
    "profit_stream = cleaned_taxi_stream \\\n",
    "    .filter(\"fare_amount >= 0 AND tip_amount >= 0\") \\\n",
    "    .withColumn(\"start_cell_id\", get_cell_udf(\"pickup_latitude\", \"pickup_longitude\")) \\\n",
    "    .withColumn(\"profit\", col(\"fare_amount\") + col(\"tip_amount\")) \\\n",
    "    .filter(\"start_cell_id IS NOT NULL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6d0e03b-c21a-4b3f-888d-0276a873cce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply 15 minute window\n",
    "median_profit_window = profit_stream \\\n",
    "    .withWatermark(\"dropoff_datetime\", \"15 minutes\") \\\n",
    "    .groupBy(\n",
    "        F.window(col(\"dropoff_datetime\"), \"15 minutes\"),\n",
    "        col(\"start_cell_id\")\n",
    "    ) \\\n",
    "    .agg(\n",
    "         expr(\"percentile_approx(profit, 0.5) as median_profit\"),\n",
    "         F.max(\"pickup_datetime\").alias(\"agg_pickup_datetime\"),\n",
    "         F.max(\"dropoff_datetime\").alias(\"agg_dropoff_datetime\")\n",
    "    )\n",
    "\n",
    "profit_agg = median_profit_window.select(\n",
    "    col(\"start_cell_id\").alias(\"cell_id\"),\n",
    "    col(\"median_profit\"),\n",
    "    col(\"window.end\").alias(\"profit_window_end\"),\n",
    "    col(\"agg_pickup_datetime\"),\n",
    "    col(\"agg_dropoff_datetime\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57b10585-0124-4d81-b759-fc9a6f01fecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_profit = profit_agg.writeStream \\\n",
    "    .format(\"memory\") \\\n",
    "    .queryName(\"profitAgg\") \\\n",
    "    .outputMode(\"complete\") \\\n",
    "    .trigger(once=True) \\\n",
    "    .start()\n",
    "\n",
    "query_profit.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8aa139e3-76da-4634-84c0-997932879485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-------------------+-------------------+--------------------+\n",
      "|cell_id|median_profit    |profit_window_end  |agg_pickup_datetime|agg_dropoff_datetime|\n",
      "+-------+-----------------+-------------------+-------------------+--------------------+\n",
      "|326.343|4.0              |2013-01-01 00:30:00|2013-01-01 00:18:30|2013-01-01 00:21:56 |\n",
      "|327.343|5.5              |2013-01-01 00:15:00|2013-01-01 00:09:00|2013-01-01 00:13:00 |\n",
      "|321.352|7.5              |2013-01-01 00:30:00|2013-01-01 00:20:00|2013-01-01 00:25:00 |\n",
      "|304.328|8.5              |2013-01-01 00:15:00|2013-01-01 00:13:47|2013-01-01 00:14:24 |\n",
      "|326.288|7.5              |2013-01-01 00:30:00|2013-01-01 00:19:36|2013-01-01 00:26:47 |\n",
      "|314.327|8.879999999999999|2013-01-01 00:15:00|2013-01-01 00:07:00|2013-01-01 00:11:00 |\n",
      "|323.313|10.0             |2013-01-01 00:15:00|2013-01-01 00:06:00|2013-01-01 00:13:22 |\n",
      "|308.344|18.0             |2013-01-01 00:30:00|2013-01-01 00:06:00|2013-01-01 00:25:00 |\n",
      "|309.311|6.5              |2013-01-01 00:30:00|2013-01-01 00:14:00|2013-01-01 00:20:00 |\n",
      "|310.322|9.5              |2013-01-01 00:30:00|2013-01-01 00:26:03|2013-01-01 00:27:23 |\n",
      "|304.334|8.5              |2013-01-01 00:30:00|2013-01-01 00:22:00|2013-01-01 00:29:00 |\n",
      "|307.330|13.0             |2013-01-01 00:30:00|2013-01-01 00:05:00|2013-01-01 00:22:00 |\n",
      "|308.348|8.0              |2013-01-01 00:30:00|2013-01-01 00:18:00|2013-01-01 00:24:08 |\n",
      "|315.329|7.5              |2013-01-01 00:30:00|2013-01-01 00:22:00|2013-01-01 00:26:00 |\n",
      "|320.315|8.0              |2013-01-01 00:15:00|2013-01-01 00:10:00|2013-01-01 00:14:32 |\n",
      "|316.304|5.5              |2013-01-01 00:30:00|2013-01-01 00:24:00|2013-01-01 00:29:00 |\n",
      "|315.304|7.3              |2013-01-01 00:15:00|2013-01-01 00:06:00|2013-01-01 00:12:56 |\n",
      "|314.352|14.0             |2013-01-01 00:30:00|2013-01-01 00:19:08|2013-01-01 00:26:56 |\n",
      "|304.337|6.5              |2013-01-01 00:30:00|2013-01-01 00:25:35|2013-01-01 00:27:28 |\n",
      "|303.331|10.4             |2013-01-01 00:30:00|2013-01-01 00:20:56|2013-01-01 00:27:24 |\n",
      "+-------+-----------------+-------------------+-------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now you can query the in-memory table and show the results:\n",
    "spark.sql(\"select * from profitAgg\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441c3a95-50a2-45bf-823c-ca598bc7f730",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col, expr\n",
    "\n",
    "empty_taxi_agg = cleaned_taxi_stream \\\n",
    "    .withColumn(\"dropoff_cell_id\", get_cell_udf(\"dropoff_latitude\", \"dropoff_longitude\")) \\\n",
    "    .filter(\"dropoff_cell_id IS NOT NULL\") \\\n",
    "    .withWatermark(\"dropoff_datetime\", \"30 minutes\") \\\n",
    "    .groupBy(\n",
    "         F.window(col(\"dropoff_datetime\"), \"30 minutes\"),\n",
    "         col(\"dropoff_cell_id\")\n",
    "    ) \\\n",
    "    .agg(expr(\"approx_count_distinct(medallion) as empty_taxis\")) \\\n",
    "    .select(\n",
    "         col(\"dropoff_cell_id\").alias(\"cell_id\"),\n",
    "         col(\"empty_taxis\"),\n",
    "         col(\"window.end\").alias(\"empty_window_end\")\n",
    "    )\n",
    "\n",
    "# Write the aggregated results to an in-memory table using complete output mode.\n",
    "query_empty = empty_taxi_agg.writeStream \\\n",
    "    .format(\"memory\") \\\n",
    "    .queryName(\"emptyAgg\") \\\n",
    "    .outputMode(\"complete\") \\\n",
    "    .trigger(once=True) \\\n",
    "    .start()\n",
    "\n",
    "query_empty.awaitTermination()\n",
    "\n",
    "# Query and display the in-memory table:\n",
    "spark.sql(\"SELECT * FROM emptyAgg\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36648758-ecb5-4cdd-b147-d74cd842032e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the in-memory tables as DataFrames.\n",
    "profit_df = spark.table(\"profitAgg\")\n",
    "empty_df = spark.table(\"emptyAgg\")\n",
    "\n",
    "# Join the two DataFrames on 'cell_id' and compute profitability.\n",
    "joined = profit_df.join(empty_df, \"cell_id\", \"inner\") \\\n",
    "    .withColumn(\"profitability\", F.col(\"median_profit\") / F.col(\"empty_taxis\"))\n",
    "\n",
    "# Select the actual aggregated pickup and dropoff timestamps, along with other required columns.\n",
    "result = joined.select(\n",
    "    col(\"agg_pickup_datetime\").alias(\"pickup_datetime\"),\n",
    "    col(\"agg_dropoff_datetime\").alias(\"dropoff_datetime\"),\n",
    "    col(\"cell_id\").alias(\"profitable_cell_id\"),\n",
    "    col(\"empty_taxis\").alias(\"empty_taxies_in_cell\"),\n",
    "    col(\"median_profit\").alias(\"median_profit_in_cell\"),\n",
    "    col(\"profitability\").alias(\"profitability_of_cell\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b41cae5-2a63-46da-9f4d-6e5d90c59157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order the result by profitability in descending order and display the top 10 rows.\n",
    "result.orderBy(F.col(\"profitability_of_cell\").desc()).show(10, truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
